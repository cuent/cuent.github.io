<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2021-12-07T21:58:24-05:00</updated><id>/feed.xml</id><title type="html">Xavier Sumba</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Graph Representation Learning notes</title><link href="/blog/2020/graph-representation-learning/" rel="alternate" type="text/html" title="Graph Representation Learning notes" /><published>2020-01-25T14:41:19-05:00</published><updated>2020-01-25T14:41:19-05:00</updated><id>/blog/2020/graph-representation-learning</id><content type="html" xml:base="/blog/2020/graph-representation-learning/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Graphs are everywhere and most knowledge can be modeled with graphs. Graphs can be understood as a complex data structure that can be used as a universal language. Therefore, as any language, graphs communicate ideas using nodes (objects) and edges (interaction); thus any complex system can be modeled by creating relationships between points. We focus in the use machine learning on graphs, but the field of network analysis provide other approaches to analyze, understand and learn from graphs.&lt;/p&gt;

&lt;h3 id=&quot;graphs-data-structure&quot;&gt;Graphs: data structure&lt;/h3&gt;
&lt;p&gt;Graphs are composed with a set of nodes \(\mathcal{V}\) on a set de edges \(\mathcal{E}\) that define a relation \(\mathcal{G}=(\mathcal{V}, \mathcal{E})\).&lt;/p&gt;

\[u,v\in\mathcal{V}\]

&lt;p&gt;Also, notice that &lt;em&gt;graph&lt;/em&gt; and &lt;em&gt;network&lt;/em&gt; are terms used interchangeably, but graphs involves properties of real-world data while a network provides mathematical properties for graphs.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Adjacency Matrix&lt;/strong&gt;: \(A\in \mathbb{R}^{\mid V\mid\times\mid V\mid}
\begin{cases}
  A_{uv}=1&amp;amp; \text{if } (u,v)\in\mathcal{E}\\
  A_{uv}=0              &amp;amp; \text{otherwise}
\end{cases}\)
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;directed&lt;/em&gt;: no symmetric&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;undirected&lt;/em&gt;: symmetric&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;weighted&lt;/em&gt;: real values \(\{0,1\}\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Graph Types&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;Simple Graph&lt;/em&gt;: relation \((u,v)\in\mathcal{E}\)&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Multi-relational&lt;/em&gt;: considers type of edge with \(R\) types, i.e. \((u,\tau,v)\in\mathcal{E}, A_\tau\) and \(A\in\mathbb{R}^{\mid V\mid\times\mid V\mid\times\mid R\mid}\)&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Attributes&lt;/em&gt;: some graphs have information associated with each node \(X\in\mathbb{R}^{\mid V\mid\times\mid m\mid}\).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;machine-learning-tasks-on-graphs&quot;&gt;Machine Learning tasks on Graphs&lt;/h3&gt;
&lt;p&gt;ML on graphs involves common ML tasks such as 1) supervised learning: predict a target output; 2) unsupervised learning: infer patterns; 3) reinforcement learning: learn to act in an environment, but there are some task on graphs that lie on these categories.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Node classification&lt;/strong&gt;: Consist in predicting a label \(y_u\) associated with a node \(u\in\mathcal{V}\).&lt;/p&gt;

    &lt;p&gt;Modeling in graphs is different since nodes are interconnected with each other and they are not i.i.d. Thus, some connection between nodes is needed. For example:&lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;homophily: nodes share attributes.&lt;/li&gt;
      &lt;li&gt;structural equivalence: nodes with similar local neighborhood structure have similar labels.&lt;/li&gt;
      &lt;li&gt;monophily: nodes with unrelated labels.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Relation prediction&lt;/strong&gt;: aka. link prediction or graph completion seeks to infer the relationship of a node with other nodes in the graph. The problems involves that given a set of nodes \(\mathcal{V}\) and an incomplete set of edges \(\mathcal{E}_{\text{train}}\in\mathcal{E}\), infer the missing edges \(\mathcal{E}\setminus\mathcal{E}_{\text{train}}\). Complexity is highly depend on the type of graph (i.e. simple graph or multi-relational graph) and it often requires inductive biases specific for each graph domain.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Clustering and community detection&lt;/strong&gt;: An unsupervised task that finds a community structure where nodes are more likely to form edges with nodes that belong to the same community. The challenge is to infer the &lt;em&gt;community structure&lt;/em&gt; given an input graph \(\mathcal{G}=(\mathcal{V},\mathcal{E})\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Graph classification/clustering&lt;/strong&gt;: Task over entire graphs. Graph classification involves that given multiple different graphs, learn predictions specific to each graph. And graph clustering (similarity matching) the goal is to learn an unsupervised measure of similarity between a set of i.i.d. graphs. Challenge is to define useful features that consider the relational structure of each datapoint.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;traditional-approaches&quot;&gt;Traditional approaches&lt;/h3&gt;
&lt;p&gt;Uses for node classification tasks&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;graph statistics&lt;/li&gt;
  &lt;li&gt;kernel methods
Link prediction&lt;/li&gt;
  &lt;li&gt;measure overlap between node neighborhoods
Clustering / community detection&lt;/li&gt;
  &lt;li&gt;spectral clustering (graph Laplacians)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;graphs-statistics-and-kernel-methods&quot;&gt;Graphs statistics and kernel methods&lt;/h4&gt;
&lt;p&gt;Extract statistics or features and use them in traditional machine learning classifiers.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Node level statistics and features&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Node degree&lt;/strong&gt;: it is the number of incident edges to a node.&lt;/p&gt;

\[d_u=\sum_{v\in V}A_{u,v}\]
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Node centrality&lt;/strong&gt;: measures the importance of a node; it takes into account the importance of a nodeâ€™s neighbors.&lt;/p&gt;

\[e_u=\frac{1}{\lambda}\sum_{v\in V}A_{u,v}e_v \forall_u \in V \text{   (eigenvector centrality)}\]

        &lt;p&gt;We can compute the vector of node centrality \(\mathbb{e}\) using the eigenvector equation with the adjacency matrix \(\lambda\mathbb{e}=A\mathbb{e}\).&lt;/p&gt;

        &lt;p&gt;We can use the eigenvector centrality to rank the likelihood that a node has visited infinity nodes on a random walk (due to the power of iteration) \(\mathbb{e}^{(t+1)}=A\mathbb{e^{(t)}}\).&lt;/p&gt;

        &lt;p&gt;Other measures:&lt;/p&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;em&gt;betweeness centrality&lt;/em&gt;: measures how often a node lies on the shortest path between two other nodes.&lt;/li&gt;
          &lt;li&gt;&lt;em&gt;closeness centrality&lt;/em&gt;: measures the average shortest path length between a node and all other nodes.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Clustering coefficient&lt;/strong&gt;:&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Motifs&lt;/strong&gt;:&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Graph-level stats -&amp;gt; kernel methods&lt;/p&gt;</content><author><name></name></author><category term="GRL" /><summary type="html">Introduction</summary></entry><entry><title type="html">Notes on the Bayesian Framework</title><link href="/blog/2019/bayesian-framework/" rel="alternate" type="text/html" title="Notes on the Bayesian Framework" /><published>2019-11-01T21:41:19-04:00</published><updated>2019-11-01T21:41:19-04:00</updated><id>/blog/2019/bayesian-framework</id><content type="html" xml:base="/blog/2019/bayesian-framework/">&lt;p&gt;Some tools:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Stochastic variational inference&lt;/li&gt;
  &lt;li&gt;Variance reduction&lt;/li&gt;
  &lt;li&gt;Normalizing flows&lt;/li&gt;
  &lt;li&gt;Gaussian processes&lt;/li&gt;
  &lt;li&gt;Scalable MCMC algorithms&lt;/li&gt;
  &lt;li&gt;Semi-implicit variational inference&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;bayesian-framework&quot;&gt;Bayesian framework&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Bayes theorem&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;

\[conditional = \frac{joint}{marginal}\]

\[p(x\mid y)=\frac{p(x,y)}{p(y)}\]

&lt;p&gt;It defines a rule for uncertainty conversion when new information arrives&lt;/p&gt;

\[posterior = \frac{likelihood \times prior}{evidence}\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Product rule&lt;/strong&gt;: any joint distribution can be expressed with conditional distributions&lt;/li&gt;
&lt;/ul&gt;

\[p(x,y,z)=p(x\mid y,z)p(y\mid z)p(z)\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Sum rule&lt;/strong&gt;: any marginal distribution can be obtained from the joint distribution by integrating out&lt;/li&gt;
&lt;/ul&gt;

\[p(y)=\int p(x,y)dx\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Statistical inference&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: given i.i.d. data \(X=\{x_i\}_{i=1}^n\) from distribution \(p(x\mid\theta)\), estimate \(\theta\)&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;Frequentist framework&lt;/strong&gt;: use maximum likelihood estimation (MLE)&lt;/li&gt;
    &lt;/ol&gt;

\[\theta_{ML}=\operatorname*{arg\,max}p(X\mid\theta)=\operatorname*{arg\,max}\prod_{i=1}^n p(x_i\mid\theta)=\operatorname*{arg\,max}\sum_i^n\log p(x_i\mid\theta)\]

    &lt;p&gt;Applicability: \(n\ll d\)&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;Bayesian framework&lt;/strong&gt;: encode uncertainty about \(\theta\) in a prior \(p(\theta)\) and apply Bayesian inference&lt;/li&gt;
    &lt;/ol&gt;

\[p(\theta\mid X)=\frac{\prod_i^n p(x_i\mid\theta)p(\theta)}{\int\prod_i^n p(x_i\mid\theta)p(\theta)d\theta}\]

    &lt;p&gt;Applicability: \(\forall_nd\)&lt;/p&gt;

    &lt;p&gt;Advantages:
    - we can encode prior knowledge/desired properties into a prior distribution
    - prior is a form of regularization
    - additionally to the point estimate of \(\theta\), posterior contains information about the uncertainty of the estimate
    - frequentist case is a limit case of Bayesian one
      \(\lim_{n/d\to\infty}p(\theta\mid x_1,\dots,x_n)=\delta(\theta-\theta_{ML})\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;bayesian-ml-models&quot;&gt;Bayesian ML models&lt;/h1&gt;
&lt;p&gt;In ML, we have \(x\) features (observed variables) and \(y\) class labels or hidden representations (hidden or latent variables) with some model parameters \(\theta\) (e.g. weights of a linear model).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Discriminative approach, models \(p(y,\theta\mid x)\)&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Cannot generate new objects since it needs \(x\) as an input and assumes that the prior over \(\theta\) does not depend on \(x\): \(p(y,\theta)=p(y\mid x,\theta)p(\theta)\)&lt;/li&gt;
      &lt;li&gt;Examples: 1) classification/regression (hidden space is small) 2) Machine translation (complex hidden space)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Generative approach, models \(p(x,y,\theta)=p(x,y\mid\theta)p(\theta)\)&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;It can generate objects (pairs \(p(x,y)\)), but it can be hard to train since the observed space is most often more complicated.&lt;/li&gt;
      &lt;li&gt;Example: Generation of text, speech, images, etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Training&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Given data points \((X_{tr}, Y_{tr})\) and a discriminative model \(p(y,\theta\mid x)\).&lt;/p&gt;

    &lt;p&gt;&lt;em&gt;Use the Bayesian framework:&lt;/em&gt;&lt;/p&gt;

\[p(\theta\mid X_{tr}, Y_{tr})=\frac{p(Y_{tr}\mid X_{tr},\theta)p(\theta)}{\int p(Y_{tr}\mid X_{tr},\theta)p(\theta) d\theta}\]

    &lt;p&gt;This results in a ensemble of algorithms rather than a single one \(\theta_{ML}\). Ensembles usually performs better than a single model.&lt;/p&gt;

    &lt;p&gt;In addition, the posterior captures all dependencies from the training data and can be used later as a new prior.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Testing&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;We have the posterior \(p(\theta\mid X_{tr},Y_{tr})\) and a new data point \(x\). We can use the predictive distribution on its hidden value \(y\)&lt;/p&gt;

\[p(y\mid x, X_{tr},Y_{tr}) = \int p(y\mid x,\theta)p(\theta\mid X_{tr},Y_{tr})d\theta\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Full Bayesian inference&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;During training the evidence \(\int p(Y_{tr}\mid X_{tr},\theta)p(\theta) d\theta\) or in testing the predictive distribution \(\int p(y\mid x,\theta)p(\theta\mid X_{tr},Y_{tr})d\theta\) might be intractable, so it is impractical or impossible to perform full Bayesian inference. In other words, there is not closed form.&lt;/p&gt;

&lt;h1 id=&quot;conjugacy&quot;&gt;Conjugacy&lt;/h1&gt;
&lt;h2 id=&quot;conjugate-distributions&quot;&gt;Conjugate distributions&lt;/h2&gt;

&lt;p&gt;Distribution \(p(y)\) and \(p(x\mid y)\) are &lt;a href=&quot;(https://en.wikipedia.org/wiki/Conjugate_prior)&quot;&gt;conjugate&lt;/a&gt; \(\iff\) \(p(y\mid x)\) belongs to the same parametric family as \(p(y)\)&lt;/p&gt;

\[p(y)\in\mathcal{A}(\alpha), p(x\mid y)\in\mathcal{B}(y) \rightarrow p(y\mid x)\in\mathcal{A}(\alpha&apos;)\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Thereâ€™s not conjugacy&lt;/strong&gt; We can perform MAP to approximate the posterior with \(\theta_{MP}\) since we donâ€™t need to calculate the normalization constant, but we cannot compute the true posterior.&lt;/li&gt;
&lt;/ul&gt;

\[\theta_{MP}=\operatorname*{arg\,max}p(\theta\mid X_{tr},Y_{tr})=\operatorname*{arg\,max}p(Y_{tr}\mid X_{tr},\theta)p(\theta)\]

&lt;p&gt;During testing:&lt;/p&gt;

\[p(y\mid x,X_{tr},Y_{tr})=\int p(y\mid x,\theta)p(\theta\mid X_{tr},Y_{tr})d\theta\approx p(y\mid x,\theta_{MP})\]

&lt;h2 id=&quot;conditional-conjugacy&quot;&gt;Conditional conjugacy&lt;/h2&gt;
&lt;p&gt;Given the model: \(p(x,\theta)=p(x\mid\theta)p(\theta)\) where \(\theta=[\theta_1,\dots,\theta_m]\)&lt;/p&gt;

&lt;p&gt;Conditional conjugacy of likelihood and prior on each \(\theta_j\) conditional on all other \(\{\theta_i\}_{i\neq j}\)&lt;/p&gt;

\[p(\theta_j\mid\theta_{i\neq j})\in\mathcal{A}(\alpha), p(x\mid\theta_j,\theta_{i\neq j})\in\mathcal{B}(\theta_j) \rightarrow p(\theta_j\mid x,\theta_{i\neq j})\in\mathcal{A}(\alpha&apos;)\]

&lt;p&gt;Check conditional conjugacy in practice:
For each \(\theta_j\)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Fix all other \(\{\theta_i\}_{i\neq j}\) (look at them as constants)&lt;/li&gt;
  &lt;li&gt;Check whether \(p(x\mid\theta)\) and \(p(\theta)\) are conjugate w.r.t. \(\theta_j\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;variational-inference&quot;&gt;Variational Inference&lt;/h1&gt;
&lt;p&gt;Given the model \(p(x,\theta)=p(x\mid \theta)p(\theta)\), find a posterior approximation \(p(\theta\mid x) \approx q(\theta)\in\mathcal{Q}\), such that:&lt;/p&gt;

\[KL(q(\theta)\parallel p(\theta\mid x)) \rightarrow \min_{q(\theta)\in\mathcal{Q}}\]

&lt;p&gt;KL is a good mismatch measure between two distributions over the &lt;strong&gt;same domain&lt;/strong&gt; (see figure). And it has the following properties:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
\[KL(q\parallel p) \geq 0\]
  &lt;/li&gt;
  &lt;li&gt;
\[KL(q\parallel p)=0 \Leftrightarrow q=p\]
  &lt;/li&gt;
  &lt;li&gt;
\[KL(q\parallel p \neq KL(p\parallel q))\]
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/kl/kl_mismatch.png&quot; alt=&quot;KL&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;evidence-lower-bound-elbo-derivation&quot;&gt;Evidence Lower Bound (ELBO) derivation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Posterior&lt;/strong&gt;: \(p(\theta\mid x)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Evidence&lt;/strong&gt;: \(p(x)\), shows the total probability of the observing data.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lower bound&lt;/strong&gt;: \(\log p(x) \geq \mathcal{L}(q(\theta))\)&lt;/li&gt;
&lt;/ul&gt;

\[\begin{align*}
  \log p(x)  &amp;amp;= \int q(\theta) \log p(x)d\theta\\
            &amp;amp;= \int q(\theta) \log\frac{p(x,\theta)}{p(\theta\mid x)}d\theta\\
            &amp;amp;= \int q(\theta) \log\frac{p(x,\theta)q(\theta)}{p(\theta\mid x)q(\theta)}d\theta\\
            &amp;amp;= \int q(\theta) \log\frac{p(x,\theta)}{q(\theta)}d\theta + \int q(\theta) \log\frac{q(\theta)}{p(\theta\mid x)}d\theta\\
            &amp;amp;= \mathcal{L}(q(\theta)) + KL(q(\theta)\parallel p(\theta\mid x))
\end{align*}\]

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\log p(x)\) does &lt;strong&gt;not depend&lt;/strong&gt; on \(q\)&lt;/li&gt;
  &lt;li&gt;\(\mathcal{L}\) and \(KL\) &lt;strong&gt;depend&lt;/strong&gt; on \(q\)&lt;/li&gt;
  &lt;li&gt;minimizing \(KL\) is the same as maximizing \(\mathcal{L}\).&lt;/li&gt;
&lt;/ul&gt;

\[KL(q(\theta)\parallel p(\theta\mid x)) \rightarrow \min_{q(\theta)\in\mathcal{Q}} \Leftrightarrow \mathcal{L}(q(\theta)) \rightarrow\max_{q(\theta)\in\mathcal{Q}}\]

&lt;h3 id=&quot;optimizing-elbo-mathcall&quot;&gt;Optimizing ELBO \(\mathcal{L}\)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt; \(\mathcal{L}(q(\theta)) \rightarrow\max_{q(\theta)\in\mathcal{Q}}\)&lt;/p&gt;

\[\begin{align*}
      \mathcal{L}(q(\theta)) &amp;amp;= \int q(\theta) \log\frac{p(x,\theta)}{q(\theta)}d\theta\\    
                             &amp;amp;= \int q(\theta) \log p(x\mid\theta)d\theta +
                                \int q(\theta) \log\frac{p(\theta)}{q(\theta)}d\theta\\
                             &amp;amp;= \mathbb{E}_{q(\theta)} \log p(x\mid\theta)
                                - KL(q(\theta)\parallel p(\theta))
  \end{align*}\]

&lt;ul&gt;
  &lt;li&gt;Data term: \(\mathbb{E}_{q(\theta)} \log p(x\mid\theta)\)&lt;/li&gt;
  &lt;li&gt;Regularizer: \(KL(q(\theta)\parallel p(\theta))\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Necessary to perform optimization w.r.t. a distribution \(\max_{q(\theta)\in\mathcal{Q}} \mathcal{L}(q(\theta))\). Hard problem! In VI, we approximate with an approximate distribution \(q\). This approximate distribution can belong to a factorized or parametric family.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Mean field approximation&lt;/strong&gt;: Factorized family, \(q(\theta)=\prod_{j=1}^m q_j(\theta_j)\), \(\theta=[\theta_1,\dots,\theta_m]\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Parametric approximation&lt;/strong&gt;: Parametric family, \(q(\theta)=q(\theta\mid \lambda)\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;mean-field-approximation&quot;&gt;Mean Field Approximation&lt;/h4&gt;
&lt;p&gt;Mean field assumes that \(\theta_1,\dots,\theta_m\) are independent.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Apply product rule to distribution \(q\): \(q(\theta)=\prod_{j=1}^m q_j(\theta_j\mid\theta_{&amp;lt;j})\)&lt;/li&gt;
  &lt;li&gt;Apply i.i.d. assumption: \(q(\theta)=\prod_{j=1}^m q_j(\theta_j)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The optimization problem becomes:&lt;/p&gt;

\[\max_{\prod_{j=1}^m q_j(\theta_j)\in\mathcal{Q}} \mathcal{L}(q(\theta))\]

&lt;p&gt;This can be solved with &lt;strong&gt;block coordinate assent&lt;/strong&gt; as follows: &lt;strong&gt;at each step fix all factors \(\{q_i(\theta_i)\}_{i\neq j}\) except one and optimize w.r.t. to it \(\max_{q_j(\theta_j)}\mathcal{L}(q(\theta))\)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Derivation&lt;/strong&gt;&lt;/p&gt;

\[\begin{align*}
      \mathcal{L}(q(\theta)) &amp;amp;= \mathbb{E}_{q(\theta)} \log p(x,\theta)
                              - \mathbb{E}_{q(\theta)} \log q(\theta) \\
                             &amp;amp;= \mathbb{E}_{q(\theta)} \log p(x,\theta)
                                -  \sum_{k=1}^m \mathbb{E}_{q_k(\theta_k)} \log q_k(\theta_k) \\
                             &amp;amp;= \mathbb{E}_{q(\theta)} \log p(x,\theta)
                                -  \mathbb{E}_{q_j(\theta_j)} \log q_j(\theta_j) + C \\
                                &amp;amp;= \{r_j(\theta_j)=\frac{1}{Z_j}\exp(\mathbb{E}_{q_{i\neq j}} \log p(x,\theta))\}\\
                                &amp;amp;= \mathbb{E}_{q_j(\theta_j)} \log r_j(\theta_j)
                                   -  \mathbb{E}_{q_j(\theta_j)} \log q_j(\theta_j) + C \\
                                &amp;amp;= - KL(q_j(\theta_j)\parallel r_j(\theta_j)) + C
  \end{align*}\]

&lt;p&gt;So, the optimization problem for step \(j\) is:&lt;/p&gt;

\[\max_{q_j(\theta_j)}\mathcal{L}(q(\theta)) = \max_{q_j(\theta_j)} - KL(q_j(\theta_j)\parallel r_j(\theta_j)) + C\]

&lt;p&gt;Where this happens when:&lt;/p&gt;

\[q_j(\theta_j) = r_j(\theta_j) = \frac{1}{Z_j}\exp(\mathbb{E}_{q_{i\neq j}} \log p(x,\theta))\]

\[\log q_j(\theta_j) = \mathbb{E}_{q_{i\neq j}} \log p(x,\theta) + C\]

&lt;p&gt;Block coordinate assent can be described in two steps 1) initialize; 2) iterate&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize: \(q(\theta)=\prod_{j=1}^m q_j(\theta_j)\)&lt;/li&gt;
  &lt;li&gt;Iterate (repeat until ELBO converge):
    &lt;ul&gt;
      &lt;li&gt;Update each factor \(q_1,\dots,q_m\): \(q_j(\theta_j)=\frac{1}{Z_j}\exp(\mathbb{E}_{q_{i\neq j}} \log p(x,\theta))\)&lt;/li&gt;
      &lt;li&gt;Compute ELBO \(\mathcal{L}(q(\theta))\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Mean-field can be applied when we can compute analytically \(\mathbb{E}_{q_{i\neq j}} \log p(x,\theta)\). In other words, applicable when we can compute the conditional conjugacy.&lt;/p&gt;

&lt;h4 id=&quot;parametric-approximation&quot;&gt;Parametric Approximation&lt;/h4&gt;
&lt;p&gt;Select a parametric family of variational distributions, \(q(\theta)=q(\theta\mid\lambda)\), where \(\lambda\) is a variational parameter.&lt;/p&gt;

&lt;p&gt;The restriction is that we need to select a family of some fixed form, and as a result:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;it might be too simple and insufficient to model the data&lt;/li&gt;
  &lt;li&gt;if it is complex enough then there is no guarantee we can train it well to fit the data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The ELBO is:&lt;/p&gt;

\[\max_{\lambda}\mathcal{L}(q\theta\mid\lambda)=\int q(\theta\mid\lambda)\log\frac{p(x\mid\theta)}{q(\theta\mid\lambda)}d\theta\]

&lt;p&gt;If weâ€™re able to calculate derivatives of ELBO w.r.t \(\theta\), then we can solve this problem using some numerical optimization solver.&lt;/p&gt;

&lt;h3 id=&quot;inference-methods&quot;&gt;Inference methods&lt;/h3&gt;
&lt;p&gt;So we have:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Full Bayesian inference: \(p(\theta\mid x)\)&lt;/li&gt;
  &lt;li&gt;MAP inference: \(p(\theta\mid x)\approx \delta (\theta-\theta_{MP})\)&lt;/li&gt;
  &lt;li&gt;Mean field variational inference: \(p(\theta\mid x)\approx q(\theta)=\prod_{j=1}^m q_j(\theta_j)\)&lt;/li&gt;
  &lt;li&gt;Parametric variational inference: \(p(\theta\mid x)\approx q(\theta)=q(\theta\mid\lambda)\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;latent-variable-model&quot;&gt;Latent variable model&lt;/h1&gt;
&lt;h2 id=&quot;mixture-of-gaussians&quot;&gt;Mixture of Gaussians&lt;/h2&gt;
&lt;p&gt;Establish a latent variable \(z_i\) for each data point \(x_i\) that denotes the \(ith\) gaussian where the model was generated.&lt;/p&gt;

&lt;p&gt;Model:&lt;/p&gt;

\[\begin{align*}
    p(X,Z\mid\theta) &amp;amp;= \prod_i^n p(x_i,z_i\mid\theta)\\
                     &amp;amp;= \prod_i^n p(x_i\mid z_i,\theta)p(z_i\mid\theta)\\
                     &amp;amp;= \prod_i^n \pi_{z_i}\mathcal{N}(x_i\mid\mu_{z_i},\sigma_{z_i}^2)
  \end{align*}\]

&lt;p&gt;where \(\pi_j=p(z_i=j)\) is the prior of the \(jth\) gaussian and \(\theta=\{\mu_j,\sigma^2_j,\pi_j\}_{j=1}^K\) are the parameters to estimate.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If \(X\) and \(Z\) are known, we can use ML. For instance:&lt;/p&gt;

\[\begin{align*}
    \theta_{ML}&amp;amp;=\operatorname*{arg\,max}_{\theta} p(X,Z\mid\theta)\\
               &amp;amp;=\operatorname*{arg\,max}_{\theta} \log p(X,Z\mid\theta)
  \end{align*}\]

&lt;ul&gt;
  &lt;li&gt;Since \(Z\) is a latent variable, we need to maximize the log of incomplete likelihood w.r.t. \(\theta\).&lt;/li&gt;
  &lt;li&gt;Instead of optimizing \(\log p(X\mid \theta)\), we optimize the variational lower bound w.r.t. to both \(\theta\) and \(q(Z)\)&lt;/li&gt;
  &lt;li&gt;This can be solved by block-coordinate algorithm a.k.a. EM-algorithm.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Variational Lower Bound:&lt;/strong&gt; \(g(\xi,\theta)\) is the variational lower bound function for \(f(x)\) iff:&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;For all \(\xi\) for all \(x\): \(f(x)\geq g(\xi,x)\)&lt;/li&gt;
    &lt;li&gt;For any \(x_0\) exists \(\xi(x_0)\) such that: \(f(x_0)=g(\xi(x0),x_0)\)&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;If we find such variational lower bound, instead of solving
\(f(x)\rightarrow\max_x\), we can interatively perform block coordinate updates of \(g(\xi, x)\).&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;
\[x_n=\operatorname*{arg\,max}_{x}g(\xi_{n-1},x)\]
    &lt;/li&gt;
    &lt;li&gt;
\[\xi_n=\xi(x_n)=\operatorname*{arg\,max}_{\xi} g(\xi,x_n)\]
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Expectation Maximization algorithm&lt;/strong&gt;
We want to solve:&lt;/p&gt;

\[\operatorname*{arg\,max}_{q,\theta}\mathcal{L}(q, \theta) = \operatorname*{arg\,max}_{q,\theta}\int q(Z)\frac{p(X,Z\mid\theta)}{q(Z)}dZ\]

&lt;p&gt;&lt;strong&gt;Algorithm&lt;/strong&gt;:
Set an initial point \(\theta_0\)&lt;/p&gt;

&lt;p&gt;Repeat iteratively 1 and 2 until convergence&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;E-step, find:
\(\begin{align*}
 q(Z)&amp;amp;=\operatorname*{arg\,max}_{q}\mathcal{L}(q,\theta_0)\\
    &amp;amp;=\operatorname*{arg\,max}_{q}{KL}(q\parallel p)\\
    &amp;amp;=p(Z\mid X,\theta_0)
  \end{align*}\)&lt;/li&gt;
  &lt;li&gt;M-step, solve:
\(\begin{align*}
 \theta_*&amp;amp;=\operatorname*{arg\,max}_{\theta}\mathcal{L}(q,\theta)\\
    &amp;amp;=\operatorname*{arg\,max}_{\theta}\mathbb{E}_Z \log p(X,Z\mid\theta)
  \end{align*}\)
    &lt;ul&gt;
      &lt;li&gt;Set \(\theta_0=\theta_*\) and go to 1&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;EM monotonically increases the lower bound and converges to a stationary point of \(\log p(X\mid\theta)\), see figure.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/em/em_optimize.gif&quot; alt=&quot;EM algorithm&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Benefits of EM&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;In some cases E-step and M-step can be solved in closed-information&lt;/li&gt;
  &lt;li&gt;Allow to build more complicated models&lt;/li&gt;
  &lt;li&gt;If true posterior \(p(Z\mid X,\theta)\) is intractable, we may search for the closest \(q(Z)\) &lt;em&gt;among tractable distributions&lt;/em&gt; by solving optimization problem&lt;/li&gt;
  &lt;li&gt;Allows to process missing data by treating them as latent variables
    &lt;ul&gt;
      &lt;li&gt;It can deal with both discrete and latent variables&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Categorical latent variables&lt;/strong&gt;
Since \(z_i\in\{1,\dots,K\}\) the marginal of a mixture of gaussians is a finite mixture of distributions:&lt;/p&gt;

\[p(x_i\mid\theta)=\sum_{k=1}^Kp(x_i\mid k,\theta)p(z_i=k\mid\theta)\]

&lt;ul&gt;
  &lt;li&gt;E-step is closed-form: \(q(z_i=k)=p(z_i=k\mid x_i,\theta)=\frac{p(x_i\mid k,\theta)p(z_i=k\mid\theta)}{\sum_{l=1}^Kp(x_i\mid l,\theta)p(z_i=l\mid\theta)}\)&lt;/li&gt;
  &lt;li&gt;M-step is a sum of finite terms: \(\mathbb{E}_Z\log p(X,Z\mid\theta)=\sum_{i=1}^n\mathbb{E}_{z_i}\log p(x_i,z_i\mid\theta)=\sum_{i=1}^n\sum_{k=1}^K q(z_i=k)\log p(x_i,k\mid\theta)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Continuous latent variables&lt;/strong&gt;
A mixture of continuous distributions&lt;/p&gt;

\[p(x_i\mid\theta)=\int p(x_i\mid z_i,\theta)p(z_i\mid\theta) dz_i\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;E-step: only done in closed form when &lt;strong&gt;conjugate distributions&lt;/strong&gt;, otherwise the true posterior is intractable&lt;/p&gt;

\[q(z_i)=p(z_i\mid x_i,\theta)=\frac{p(x_i\mid z_i,\theta)p(z_i\mid\theta)}{\int p(x_i\mid z_i,\theta)p(z_i\mid\theta) dz_i}\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Typically continuous latent variable are used for dimensionality reduction a.k.a. &lt;em&gt;representation learning&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;log-derivative-trick&quot;&gt;Log-derivative trick&lt;/h1&gt;

\[\frac{\partial}{\partial x}p(y\mid x)=p(y\mid x)\frac{\partial}{\partial x}\log p(y\mid x)\]

&lt;p&gt;For example, we commonly find expressions as follows:&lt;/p&gt;

\[\begin{align*}
    \frac{\partial}{\partial x}\int p(y\mid x)h(x,y)dy &amp;amp;= \int \frac{\partial}{\partial x} p(y\mid x)h(x,y)dy\\
                                  &amp;amp;= \int \left(h(x,y)\frac{\partial}{\partial x} p(y\mid x) + p(y\mid x)\frac{\partial}{\partial x} h(x,y) \right)dy \\
                                  &amp;amp;= \int p(y\mid x)\frac{\partial}{\partial x} h(x,y) dy + \int h(x,y)\frac{\partial}{\partial x} p(y\mid x)dy \\
                                  &amp;amp;= \int p(y\mid x)\frac{\partial}{\partial x} h(x,y) dy + \int p(y\mid x)h(x,y)\frac{\partial}{\partial x} \log p(y\mid x)dy
  \end{align*}\]

&lt;p&gt;Now, the first term can be replaced with Monte Carlo estimate of expectation. Using the log-derivative trick, the second expectation can also be estimated via Monte Carlo.&lt;/p&gt;

&lt;h1 id=&quot;score-function&quot;&gt;Score function&lt;/h1&gt;

&lt;p&gt;It is the gradient of the log-likelihood function with respect to the parameter vector. Since it has zero mean, the value \(z_i^*\) in \(\nabla_{\phi}\log q(z_i^*\mid\theta)\) oscillates around zero.&lt;/p&gt;

\[\begin{align*}
    \nabla_{\phi}\log q(z_i\mid\theta)
  \end{align*}\]

&lt;p&gt;Proof it has zero mean:&lt;/p&gt;

\[\begin{align*}
  \int q(z_i\mid\theta)\nabla_{\phi}\log q(z_i\mid\theta) d z_i&amp;amp;=\int\frac{q(z_i\mid\theta)}{q(z_i\mid\theta)}\nabla_{\phi}q(z_i\mid\theta)d z_i\\
                                                              &amp;amp;= \nabla_{\phi}\int q(z_i\mid\theta)dz_i\\
                                                              &amp;amp;= \nabla_{\phi} 1 =0
\end{align*}\]

&lt;h1 id=&quot;reinforce&quot;&gt;REINFORCE&lt;/h1&gt;</content><author><name></name></author><category term="Bayesian-inference" /><summary type="html">Some tools: Stochastic variational inference Variance reduction Normalizing flows Gaussian processes Scalable MCMC algorithms Semi-implicit variational inference</summary></entry><entry><title type="html">Expectation Propagation Notes</title><link href="/blog/2019/expectation-propagation/" rel="alternate" type="text/html" title="Expectation Propagation Notes" /><published>2019-07-25T21:41:19-04:00</published><updated>2019-07-25T21:41:19-04:00</updated><id>/blog/2019/expectation-propagation</id><content type="html" xml:base="/blog/2019/expectation-propagation/">&lt;p&gt;Commonly in probabilistic models, we deal with expectations that are either too hard to compute or intractable. In Bayesian inference setting, we usually need to calculate the posterior \(p(z\mid x)\) for parameter estimation or the evidence \(p(x)\) for model selection, where \(z\) is a latent variable and \(x\) is known. We can use approximate inference to solve this complex integrals. There is many work that have been done in this area, but approximate methods can be classified in deterministic and sampling methods. The former evaluates the integral in several locations and constructs an approximate function. The latter relies in the law of large numbers and given enough samples, the integral will converge to the true value.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Sampling methods: Monte Carlo methods such as Importance sampling, Gibbs sampling, MCMC&lt;/li&gt;
  &lt;li&gt;Deterministic methods: Variational inference, Laplace approximation, Expectation Propagation&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This notes include explanations for ADF and Expectation Propagation.&lt;/p&gt;

&lt;h2 id=&quot;assumed-density-filtering-adf&quot;&gt;Assumed-density Filtering (ADF)&lt;/h2&gt;

&lt;p&gt;ADF (aka. moment matching, online Bayesian learning and weak marginalization) can be used when given the joint \(p(x, z)\), we want to calculate the posterior over the latent variable \(p(z \mid x)\) and the evidence \(p(x)\). This is a common task in statistical machine learning where we want to fit a parametric distribution.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The common setting&lt;/strong&gt;: we are given a set of data points \(D=x_1,\dots,x_n\), which we assume are i.i.d. Thus, we can model the joint distribution as the product of its observations and the prior \(p(D,z) = p(z)\prod_i p(x_i\mid z)\).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Factorization&lt;/strong&gt;: We can factorize the joint distribution as needed, but it is recommendable that &lt;strong&gt;each factor is simple&lt;/strong&gt; enough for being propagated. Also the &lt;strong&gt;fewer terms&lt;/strong&gt;, entails fewer approximations. In general, we can define the joint distribution as follows where \(t_0\) is the prior.&lt;/p&gt;

\[p(D,z) = \prod_{i=0}^n t_i(z)\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Choose a parametric approximating distribution&lt;/strong&gt;: our goal is to approximate the posterior with a simple distribution; \(p(z\mid D) \approx q(z)\).&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;This distribution has to belong to the exponential family, so we can propagate its sufficient statistics.&lt;/li&gt;
      &lt;li&gt;Pick \(q\) based in the nature and domain of \(z\).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Incorporate each \(t_i\) term&lt;/strong&gt;: Sequence and incorporate the term \(t_i\) into the approximate posterior \(q(z\)) going from an old posterior to a new posterior.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;incorporate&lt;/strong&gt;: \(\hat p(z) = \frac{q(z)t_i(z)}{\int_z q(z)t_i(z) dz}\)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;from old to new&lt;/strong&gt;: \(\min D_{KL}(\hat p \parallel q^{new})\), which equivalent to match the moments.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;intuition&quot;&gt;Intuition&lt;/h3&gt;
&lt;p&gt;Here is a graphical example of ADF in practice.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;\(q(z)\) can be initialized to \(1\), and itâ€™s not necessary to approximate.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/adf/adf_step1.png&quot; alt=&quot;ADF step 1&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Incorporate \(t_1\), resulting in a one-step step posterior \(\hat p\). We approximate \(\hat p\) with \(q^{new}\).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/adf/adf_step2.png&quot; alt=&quot;ADF step 2&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Repeat step 2, including \(t_2\).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/adf/adf_step3.png&quot; alt=&quot;ADF step 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can notice that thereâ€™s a dependence in the order of the data points; &lt;strong&gt;order matters&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The error of ADF tend to increase when similar data points are processed&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;expectation-propagation&quot;&gt;Expectation Propagation&lt;/h2&gt;
&lt;p&gt;Expectation Propagation (&lt;a href=&quot;https://arxiv.org/pdf/1301.2294.pdf&quot;&gt;Minka&lt;/a&gt;., NIPS 2001) is a generalization of ADF. We can notice that ADF is an iterative method that performs a one-pass to all data points. EP solves this problem by performing iterative refinements.&lt;/p&gt;

&lt;p&gt;ADF:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Treat \(t_i\) as it is.&lt;/li&gt;
  &lt;li&gt;Approximate \(q(z)\).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;EP:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Approximate \(t_i\) with \(\tilde t_i\).&lt;/li&gt;
  &lt;li&gt;Use exact posterior&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This refinements are always possible. It is the ratio of the new posterior to the old posterior times a constant:&lt;/p&gt;

\[\tilde t_i(z)=Z\frac{q^{new}(z)}{q(z)}\]

&lt;p&gt;Letâ€™s see how this looks in practice:&lt;/p&gt;

&lt;p&gt;First, letâ€™s derive an intuition of ADF using \(\tilde t_i\).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;We approximate \(t_1\) with \(\tilde t_1\) using the prior \(t_0=1\)m and go from \(q^{old}\) to \(q^{new}\).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/adf/adf_approx_step1.png&quot; alt=&quot;ADF approx step 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/adf/adf_approx_step2.png&quot; alt=&quot;ADF approx step 2&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><category term="Bayesian-inference" /><summary type="html">Commonly in probabilistic models, we deal with expectations that are either too hard to compute or intractable. In Bayesian inference setting, we usually need to calculate the posterior \(p(z\mid x)\) for parameter estimation or the evidence \(p(x)\) for model selection, where \(z\) is a latent variable and \(x\) is known. We can use approximate inference to solve this complex integrals. There is many work that have been done in this area, but approximate methods can be classified in deterministic and sampling methods. The former evaluates the integral in several locations and constructs an approximate function. The latter relies in the law of large numbers and given enough samples, the integral will converge to the true value.</summary></entry><entry><title type="html">Probabilistic Graphical Models</title><link href="/blog/2019/pgm-intro/" rel="alternate" type="text/html" title="Probabilistic Graphical Models" /><published>2019-05-17T21:41:19-04:00</published><updated>2019-05-17T21:41:19-04:00</updated><id>/blog/2019/pgm-intro</id><content type="html" xml:base="/blog/2019/pgm-intro/">&lt;p&gt;A graphical model is a method for modeling probability distributions under certain uncertainty.&lt;/p&gt;

&lt;h2 id=&quot;toolbox&quot;&gt;Toolbox:&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Representation:&lt;/strong&gt; model uncertainty and encode domain knowledge&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Inference:&lt;/strong&gt; answer questions \(P(X\mid m)\), where m is the model or data&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Learning:&lt;/strong&gt; what model fits my data \(m = \operatorname*{argmax}_{m\in M} F(D,m)\).&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;benefits&quot;&gt;Benefits:&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Efficient&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;(Expensive)&lt;/strong&gt; The &lt;a href=&quot;https://en.wikipedia.org/wiki/Chain_rule_(probability)&quot;&gt;chain rule&lt;/a&gt; (aka product rule) allows to calculate joint probabilities.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;(Cheaper)&lt;/strong&gt; Using GM, we can model only those dependencies inferred by the graph, generating fewer parameters; encodes independence.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Encode domain knowledge through priors and incorporate them in inference via Bayes theorem.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;gms-vs-pgms&quot;&gt;GMs vs PGMs:&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;GMs use multivariate function.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;PGMs use multivariate distributions.&lt;/p&gt;

    &lt;h3 id=&quot;structure&quot;&gt;Structure&lt;/h3&gt;

    &lt;ol&gt;
      &lt;li&gt;Edges represent relationship among the RVs.&lt;/li&gt;
      &lt;li&gt;Directed nodes represent &lt;strong&gt;causality&lt;/strong&gt; while undirected nodes represent &lt;strong&gt;correlation&lt;/strong&gt;.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bayesian-network-and-markov-random-field&quot;&gt;Bayesian Network and Markov Random Field&lt;/h2&gt;

&lt;h3 id=&quot;bayesian-network&quot;&gt;Bayesian Network&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/bayesian-network.png&quot; alt=&quot;Bayesian Network&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It is a directed acyclic graph (DAG) where each node has a &lt;a href=&quot;https://en.wikipedia.org/wiki/Markov_blanket&quot;&gt;Markov blanked&lt;/a&gt; (its parents, children and childrenâ€™s parents).&lt;/li&gt;
  &lt;li&gt;A node is &lt;em&gt;conditionally independent&lt;/em&gt; of the nodes &lt;strong&gt;outside&lt;/strong&gt; its Markov Blanket.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Joint probability distribution&lt;/em&gt; is determined by the local conditional probabilities as well as the graph structure.&lt;/li&gt;
  &lt;li&gt;Model &lt;em&gt;can&lt;/em&gt; be used to generate new data.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;markov-random-field&quot;&gt;Markov Random Field&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/markov-random-field.png&quot; alt=&quot;Markov Random Field&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It is an undirected graph.&lt;/li&gt;
  &lt;li&gt;A node is conditionally independent of the other graph nodes, except for its &lt;strong&gt;immediate neighbors&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;To determine the joint probability distribution, we need to know local contingency functions (&lt;em&gt;potentials&lt;/em&gt;) as well as structural &lt;em&gt;cliques&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;This model &lt;em&gt;cannot&lt;/em&gt; explicitly generate new data.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="Bayesian-inference" /><summary type="html">A graphical model is a method for modeling probability distributions under certain uncertainty.</summary></entry><entry><title type="html">CS224W notes - Machine learning with graphs</title><link href="/blog/2019/compcs224w-notes/" rel="alternate" type="text/html" title="CS224W notes - Machine learning with graphs" /><published>2019-05-17T21:41:19-04:00</published><updated>2019-05-17T21:41:19-04:00</updated><id>/blog/2019/compcs224w-notes</id><content type="html" xml:base="/blog/2019/compcs224w-notes/">&lt;h2 id=&quot;introduction-and-graph-structure&quot;&gt;&lt;a href=&quot;(http://web.stanford.edu/class/cs224w/slides/01-intro.pdf)&quot;&gt;Introduction and graph structure&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;why-graphs&quot;&gt;Why graphs?&lt;/h3&gt;
&lt;p&gt;Networks are general languages for describing complex systems of interacting entities. In other words, a network is a universal language for describing complex data.&lt;/p&gt;

&lt;p&gt;Network structure affects the robustness of a system&lt;/p&gt;

&lt;p&gt;Most real networks are sparse&lt;/p&gt;

&lt;p&gt;Tasks to perform in graphs:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;node classification&lt;/li&gt;
  &lt;li&gt;link prediction&lt;/li&gt;
  &lt;li&gt;community detection&lt;/li&gt;
  &lt;li&gt;network similarity&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Embedding nodes:&lt;/strong&gt; map nodes to \(d\)-dimensional embeddings. Thus, nodes wit similar network neighbourhoods are embedded close together.&lt;/p&gt;

&lt;p&gt;Terminology:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Networks refer to a real system, e.g. Social Networks, Web.&lt;/li&gt;
  &lt;li&gt;Graph is a mathematical representation of a network e.g. graph, vertex, edge&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Graphs can be directed (followers on twitter) or undirected (friends on Facebook)&lt;/p&gt;

&lt;p&gt;Node degrees:
  Undirected:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;node degree: the number of edges adjacent to node i&lt;/li&gt;
  &lt;li&gt;avg. degree&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Directed:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;in-degree&lt;/li&gt;
  &lt;li&gt;out-degree&lt;/li&gt;
  &lt;li&gt;the total degree of a node is the sum of in and out-degrees&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Complete Graph&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;maximum number of edges in an undirected graph on $N$ nodes is \(E_max=\frac{N(N-1)}{2}\) and when the number of edges is $E=E_max$, the undirected graph is called compete graph.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Bipartite Graph&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;It is a graph whose nodes can be divided into two disjoints sets $U$ and $V$, which are independent sets.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Representing Graphs
  Adjacency matrix&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(A_{ij}=1\) if there is a link from node \(i\) to \(j\)&lt;/li&gt;
  &lt;li&gt;\(A_{ij}=0\) otherwise&lt;/li&gt;
  &lt;li&gt;they are sparse&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Edge List&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;graph as a set of edges&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Adjacency list&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;each row is a node and its line is the connected nodes
1:
2: 3,4
3: 2,4
4: 5&lt;/li&gt;
  &lt;li&gt;Easier to work with if network is large or sparse&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Edge attributes&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;weight (frequency of communication)&lt;/li&gt;
  &lt;li&gt;raking (best friend, 2nd best friend)&lt;/li&gt;
  &lt;li&gt;type (friend, relative)&lt;/li&gt;
  &lt;li&gt;Sign (Friend vs Foe)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other types of graphs:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;self-edges: contain self-loops (proteins, hyperlinks)&lt;/li&gt;
  &lt;li&gt;multigraph: more than one edge between nodes (communication, collaboration)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Connectivity:
  Disconnected graph&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a graph can become a disconnected graph, if the a subgraph becomes isolated. Thus it has more than one componentâ€¦&lt;/li&gt;
  &lt;li&gt;bridge edge: if we delete an edge,&lt;/li&gt;
  &lt;li&gt;articulation node: if we erase a node&lt;/li&gt;
  &lt;li&gt;Each component can be represented in a block-diagonal form&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Strongly connected directed graph&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;has a path from each node to every other node and vice-versa.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Weakly connected directed graph&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;is connected if we disregard the edge directions&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;properties-of-networks-and-random-graph-models&quot;&gt;&lt;a href=&quot;(http://web.stanford.edu/class/cs224w/slides/02-gnp-smallworld.pdf)&quot;&gt;Properties of networks and random graph models&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;how-to-measure-a-network&quot;&gt;How to Measure a Network&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Degree distribution \(p(k)\): probability that a randomly node has degree \(k\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;\(N_k\rightarrow\): number of nodes with degree \(k\)&lt;/p&gt;

\[p(k)=\frac{N_k}{N}\]

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; directed graphs have separate in- and out-degree distributions&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Path: sequence of nodes in which each node is linked to the next one.&lt;/li&gt;
&lt;/ul&gt;

\[P_n=\{i_0,\dots,i_n\}\]

\[P_n=\{(i_0,i_1),\dots,(i_{n-1},i_n)\}\]

&lt;ul&gt;
  &lt;li&gt;Distance between a pair of nodes \(h_{A,B}\): number of edges along the shortest path connecting the nodes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If node are not connected, distance is defined as &lt;em&gt;zero&lt;/em&gt; or &lt;em&gt;infinity&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Directed graphs, paths need to follow the direction of the arrows, and as a consequence, distance is not symmetric \(h_{B,C}\neq h_{c,B}\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Diameter: shortest path distance between any pair of nodes in a graph&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Average path length \(\bar h\):&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\bar h= \frac{1}{2E_{max}}\sum_{i,j\neq i}h_{ij}\]

&lt;p&gt;\(E_{max}\): max number of edges (total number of node pairs) \(=\frac{n(n-1)}{2}\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Clustering Coefficient&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="GRL" /><summary type="html">Introduction and graph structure</summary></entry><entry><title type="html">Sampling methods notes</title><link href="/blog/2019/sampling-methods/" rel="alternate" type="text/html" title="Sampling methods notes" /><published>2019-05-17T21:41:19-04:00</published><updated>2019-05-17T21:41:19-04:00</updated><id>/blog/2019/sampling-methods</id><content type="html" xml:base="/blog/2019/sampling-methods/">&lt;h1 id=&quot;monte-carlo-methods&quot;&gt;Monte Carlo Methods&lt;/h1&gt;

&lt;p&gt;Randomized algorithms have two categories: Las Vegas and Monte Carlo algorithms.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;Las Vegas:&lt;/em&gt; always return an answer if available.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Monte Carlo&lt;/em&gt;: return answers with a random amount of error.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;monte-carlo-sampling&quot;&gt;Monte Carlo sampling&lt;/h2&gt;
&lt;p&gt;Probability distributions are commonly used in Machine Learning. Sampling provides a flexible way to approximate many sums and integrals. When a sum or integral cannot be computed, it is possible to approximate with &lt;strong&gt;Monte Carlo sampling&lt;/strong&gt;. The main idea is to see the sum or integral as an expectation, and approximate it by an avearge.&lt;/p&gt;

\[s=\sum_x p(x)f(x)=\mathbb{E}_p[f(\mathbf{x})]\]

\[s=\int p(x)f(x) dx=\mathbb{E}_p[f(\mathbf{x})]\]

&lt;p&gt;, where \(p\) is a PMF or PDF over the random variable \(\mathbf{x}\).&lt;/p&gt;

&lt;p&gt;\(s\) can be approximated by drawing \(n\) samples \(x^{(1)}, \dots, x^{(n)}\) from \(p\) and calculate the &lt;strong&gt;empirical average&lt;/strong&gt; as follows:&lt;/p&gt;

\[\hat s_n=\frac{1}{n}\sum_{i=1}^n f(x^{(i)})\]

&lt;p&gt;Some properties:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Estimator \(\hat s\) is unbiased.&lt;/li&gt;
  &lt;li&gt;By the &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Law_of_large_numbers&quot;&gt;law of large numbers&lt;/a&gt;&lt;/em&gt;, we say that if \(x^{(i)}\) are i.i.d. the average converges to the expected values (\(\lim_{n\to\infty} \hat s_n=s\)).&lt;/li&gt;
  &lt;li&gt;By calculating the variance \(Var[\hat s_n]\) as \(n\) increases, we can estimate the uncertainty of the Monte Carlo approximation.&lt;/li&gt;
  &lt;li&gt;MC sampling relies in sampling from \(p\). When &lt;em&gt;sampling&lt;/em&gt; \(p\) &lt;em&gt;is not possible&lt;/em&gt;, importance sampling or MCMC can be used.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;importance-sampling&quot;&gt;Importance Sampling&lt;/h2&gt;
&lt;p&gt;In Monte Carlo, we can use any decomposition of \(p(\mathbf{x})\) and \(f(\mathbf{x})\) since \(f\) can also be a probability (what factor plays which role of \(p\) or \(f\)). We can even have a different decomposition as follows (i.e. we sample \(q\) and average \(\frac{pf}{q})\):&lt;/p&gt;

\[p(\mathbf{x})f(\mathbf{x})=q(\mathbf{x})\frac{p(\mathbf{x})f(\mathbf{x})}{q(\mathbf{x})}\]

&lt;p&gt;However, we might not be able to sample from \(p\) or we can pick another distribution to reach an optimal approximation. This optimal choice is \(q*\), know as &lt;strong&gt;optimal importance sampling&lt;/strong&gt;. So, we replace the empirical average with an &lt;strong&gt;importance sampling estimator&lt;/strong&gt;:&lt;/p&gt;

\[\hat s_q=\frac{1}{n}\sum_{i=1, \mathbf{x}^{(i)}\sim q}^n \frac{p(\mathbf{x}^{(i)})f(\mathbf{x}^{(i)})}{q(\mathbf{x}^{(i)})}\]

&lt;p&gt;Essentially, any distribution \(q\) is valid. However, the choice of \(q\) can be sensitive to the variance of the &lt;em&gt;importance sampling estimator&lt;/em&gt;.&lt;/p&gt;

&lt;h4 id=&quot;biased-importance-sampling&quot;&gt;Biased Importance Sampling&lt;/h4&gt;
&lt;p&gt;BIS doesnâ€™t require to normalize \(p\) or \(q\), the estimator is given by:&lt;/p&gt;

\[\hat s_{BIS}=\frac{\sum_{i=1}^n\frac{\tilde p(\mathbf{x^{(i)}})}{\tilde q(\mathbf{x^{(i)}})}f(\mathbf{x^{(i)}})}{\sum_{i=1}^n\frac{\tilde p(\mathbf{x^{(i)}})}{\tilde q(\mathbf{x^{(i)}})}}\]

&lt;p&gt;, where \(\tilde p\) and \(\tilde q\) are the unnormalized forms of \(p\) and \(q\). We take n samples \(\mathbf{x^{(i)}}\) from \(q\).&lt;/p&gt;

&lt;p&gt;In general importance sampling is handy when it comes to:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;accelerate training in neural language models with a large vocabulary.&lt;/li&gt;
  &lt;li&gt;estimate a partition function.&lt;/li&gt;
  &lt;li&gt;estimate log-likelihood in deep directed models.&lt;/li&gt;
  &lt;li&gt;improve estimates of the gradient of the cost function.&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- 
## Markov Chain Monte Carlo

## Gibbs Sampling --&gt;</content><author><name></name></author><category term="Bayesian-inference" /><summary type="html">Monte Carlo Methods</summary></entry><entry><title type="html">Linear Algebra</title><link href="/blog/2019/linear_algebra/" rel="alternate" type="text/html" title="Linear Algebra" /><published>2019-05-15T22:41:19-04:00</published><updated>2019-05-15T22:41:19-04:00</updated><id>/blog/2019/linear_algebra</id><content type="html" xml:base="/blog/2019/linear_algebra/">&lt;p&gt;Some interesting links:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;(https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)&quot;&gt;Matrix cookbook&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;(https://people.maths.ox.ac.uk/gilesm/files/NA-08-01.pdf)&quot;&gt;Matrix derivatives&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notes of &lt;a href=&quot;(http://www.deeplearningbook.org/contents/linear_algebra.html)&quot;&gt;chapter 2&lt;/a&gt; of Deep Learning book.&lt;/p&gt;

&lt;h4 id=&quot;mathematical-objects&quot;&gt;Mathematical objects&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Scalar:&lt;/strong&gt; single number \(x=1\)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Vector:&lt;/strong&gt; array of numbers \(\mathbf{x}=\begin{vmatrix}x_1\\\vdots\\x_n\end{vmatrix}\)&lt;/p&gt;

    &lt;p&gt;\(\mathbf{x_{-1}}\): ignore element \(x_1\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Matrix:&lt;/strong&gt; 2D array of numbers \(\mathbf{A}\in\mathbb{R}^{mxn}\)&lt;/p&gt;

    &lt;p&gt;horizontal coordinate (all), ith row: \(\mathbf{A}_{i,:}\)&lt;/p&gt;

    &lt;p&gt;vertical coordinate (all), ith column: \(\mathbf{A}_{:,i}\)&lt;/p&gt;

    &lt;p&gt;value: \(f(\mathbf{A})_{i,j}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Tensor:&lt;/strong&gt; array with more than two axes \(\mathbf{A}\)&lt;/p&gt;

    &lt;p&gt;value: \(\mathbf{A}_{i,j,k}\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;transpose&quot;&gt;Transpose&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Mirror across &lt;em&gt;main diagonal&lt;/em&gt; \(\mathbf{A} \rightarrow \mathbf{A}^\intercal\)&lt;/li&gt;
  &lt;li&gt;Scalar matrix, one item \(\mathbf{a}=\mathbf{a}^\intercal\)&lt;/li&gt;
  &lt;li&gt;Vector \(\mathbf{x}^\intercal\)&lt;/li&gt;
  &lt;li&gt;Matrix product \((\mathbf{A}\mathbf{B})^\intercal=\mathbf{B}^\intercal\mathbf{A}^\intercal\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;addition&quot;&gt;Addition&lt;/h4&gt;
&lt;p&gt;If \(\mathbf{A}\) and \(\mathbf{B}\) same shape, \(\mathbf{C}=\mathbf{A}+\mathbf{B}\), where \(\mathbf{C}_{i,j}=\mathbf{A}_{i,j}+\mathbf{B}_{i,j}\).&lt;/p&gt;

&lt;h4 id=&quot;scalar-addition-and-multiplication&quot;&gt;Scalar addition and multiplication&lt;/h4&gt;
&lt;p&gt;\(\mathbf{D}=a\cdot\mathbf{B}+c\), where \(\mathbf{D}_{i,j}=a\cdot\mathbf{B}_{i,j}+c\)&lt;/p&gt;

&lt;h4 id=&quot;addition-matrix-and-vector&quot;&gt;Addition matrix and vector&lt;/h4&gt;
&lt;p&gt;\(\mathbf{C}=\mathbf{A}+\mathbf{b}\), where \(\mathbf{C}_{i,j}=\mathbf{A}_{i,j}+\mathbf{b}_j\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;broadcasting&lt;/strong&gt;: \(\mathbf{b}\) is addded to each &lt;strong&gt;row&lt;/strong&gt; of the matrix \(\mathbf{A}\).&lt;/p&gt;

&lt;h4 id=&quot;operations&quot;&gt;Operations&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Matrix product \(\mathbf{C}=\mathbf{A}\mathbf{B} \rightarrow \mathbf{C}_{m\times p}=\mathbf{A}_{m\times n}\mathbf{B}_{n\times p}\) and \(\mathbf{C}_{i,j}=\sum_k\mathbf{A}_{i,k}\mathbf{B}_{k,j}\)&lt;/p&gt;

    &lt;p&gt;Vectors of the same size: \(\mathbf{x}^\intercal\mathbf{y}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Elementwise product / Hadamard product \(\mathbf{A}\odot\mathbf{B}\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;properties&quot;&gt;Properties&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Distributive: \(\mathbf{A}(\mathbf{B}+\mathbf{C})=\mathbf{A}\mathbf{B}+\mathbf{A}\mathbf{C}\)&lt;/li&gt;
  &lt;li&gt;Associative: \(\mathbf{A}(\mathbf{B}\mathbf{C})=(\mathbf{A}\mathbf{B})\mathbf{C}\)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Commutative: &lt;strong&gt;not&lt;/strong&gt; \(\mathbf{A}\mathbf{B}\neq \mathbf{B}\mathbf{A}\) (not always)&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;yes&lt;/strong&gt; for vectors \(\rightarrow\) \(\mathbf{x}^\intercal \mathbf{y}=\mathbf{y}^\intercal\mathbf{x}\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;linear-equations&quot;&gt;Linear equations&lt;/h4&gt;

&lt;p&gt;\(\mathbf{A}\mathbf{x}=\mathbf{b}\) (notation compact)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{A}\in\mathbb{R}^{m\times n}\) known&lt;/li&gt;
  &lt;li&gt;\(\mathbf{x}\in\mathbb{R}^m\) variable&lt;/li&gt;
  &lt;li&gt;\(\mathbf{b}\in\mathbb{R}^m\) known&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notation not compact, equations:&lt;/p&gt;

\[A_{1,:}\mathbf{x}=b_1 \rightarrow A_{1,1}x_1+\dots+A_{1,n}x_n=b_1\\
 \vdots\\
 A_{m,:}\mathbf{x}=b_m \rightarrow A_{m,1}x_1+\dots+A_{m,n}x_n=b_m\]

&lt;h4 id=&quot;identity-matrix&quot;&gt;Identity matrix&lt;/h4&gt;
&lt;p&gt;\(\mathbf{I}_n\in\mathbb{R}^{nxn} \rightarrow \mathbf{I}_n\mathbf{x}=\mathbf{x}\:\:\:\:\:\:\: \forall_{\mathbf{x}}\in\mathbb{R}^n\)&lt;/p&gt;

&lt;h4 id=&quot;inverse-matrix&quot;&gt;Inverse Matrix&lt;/h4&gt;
&lt;p&gt;\(A^{-1}A=\mathbf{I}_n\), \(AA^{-1}=\mathbf{I}_n\), for square matrix left and right are the same.&lt;/p&gt;

&lt;p&gt;For example:
\(\begin{align}
A\mathbf{x}&amp;amp;=\mathbf{b} \\
A^{-1}A\mathbf{x}&amp;amp;=A^{-1}\mathbf{b} \\
\mathbf{I}_n\mathbf{x}&amp;amp;=A^{-1}\mathbf{b}\\
\mathbf{x}&amp;amp;=A^{-1}\mathbf{b}
\end{align}\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Should &lt;strong&gt;not&lt;/strong&gt; be used in practical applications because &lt;strong&gt;limited precision&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;\(A^{-1}\) might not be possible to find (singular matrix).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Matrix should be &lt;strong&gt;square and singular&lt;/strong&gt;. If not, we cannot get \(A^{-1}\).&lt;/p&gt;
&lt;h4 id=&quot;linear-combination&quot;&gt;Linear Combination&lt;/h4&gt;
&lt;p&gt;\({\mathbf{v}^{(1)},\dots,\mathbf{v}^{(n)}}\) Given by multiplying each vector \(\mathbf{v}^{(i)}\) by a scalar and adding.&lt;/p&gt;

\[\sum_i c_i\mathbf{v}^{(i)}\]

&lt;h5 id=&quot;span&quot;&gt;Span&lt;/h5&gt;
&lt;p&gt;Set of all points obtained by linear combination of the original vectors&lt;/p&gt;

&lt;p&gt;\(A\mathbf{x}=\mathbf{b} \rightarrow\) solution if \(\mathbf{b}\) is in the &lt;strong&gt;span&lt;/strong&gt; (known as &lt;strong&gt;column space&lt;/strong&gt; / &lt;strong&gt;range&lt;/strong&gt; of \(A\)) of columns \(A\)&lt;/p&gt;

&lt;p&gt;\(A\) square matrix \(m=n\) and all columns linear independent.&lt;/p&gt;

&lt;h4 id=&quot;linear-dependence&quot;&gt;Linear Dependence&lt;/h4&gt;
&lt;p&gt;Same column space / a combination&lt;/p&gt;
&lt;h4 id=&quot;linear-independence&quot;&gt;Linear Independence&lt;/h4&gt;
&lt;p&gt;No vector in the set is a &lt;strong&gt;linear combination&lt;/strong&gt; of the other vectors.&lt;/p&gt;
&lt;h4 id=&quot;square-matrix&quot;&gt;Square matrix&lt;/h4&gt;
&lt;p&gt;\(A \in\mathbb{R}^{m\times n} m=n\)&lt;/p&gt;
&lt;h4 id=&quot;singular-matrix&quot;&gt;Singular matrix&lt;/h4&gt;
&lt;p&gt;Matrix with linear independent columns&lt;/p&gt;
&lt;h4 id=&quot;norms&quot;&gt;Norms&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Norms are functions mapping vectors to non-negative values (distance from origin to point \(\mathbf{x}\))&lt;/li&gt;
  &lt;li&gt;Measure the size of a vector&lt;/li&gt;
  &lt;li&gt;Any function \(f\) is a norma as long as:
    &lt;ol&gt;
      &lt;li&gt;\(f(\mathbf{x})=0 \rightarrow \mathbf{x}=0\).&lt;/li&gt;
      &lt;li&gt;\(f(\mathbf{x} + \mathbf{y}) \leq f(\mathbf{x}) + f(\mathbf{y})\) triangle inequality&lt;/li&gt;
      &lt;li&gt;\(\forall \alpha\in\mathbb{R}, f(\alpha\mathbf{x}) = \mid\alpha\mid f(\mathbf{x})\).&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;list&quot;&gt;List:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(L^p\) norm&lt;/strong&gt;: \(\mid\mid x\mid\mid_p=(\sum_i\mid x_i\mid)^{\frac{1}{p}}\) where \(p\in\mathbb{R}, p\geq 1\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(L^2\) Euclidean norm (distance)&lt;/strong&gt;: \(\parallel\mathbf{x}\parallel_2=\parallel\mathbf{x}\parallel=\mathbf{x}^\intercal\mathbf{x}\)
    &lt;ul&gt;
      &lt;li&gt;increases really slowly near the original&lt;/li&gt;
      &lt;li&gt;squared \(L^2\) norm is better to work: 1) mathematically and 2) computationally.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(L^1\) norm&lt;/strong&gt;: \(\parallel\mathbf{x}\parallel_1=\sum_i\mid x_i\mid\)
    &lt;ul&gt;
      &lt;li&gt;chooses a function that grows at the &lt;strong&gt;same rate&lt;/strong&gt; in all locations.&lt;/li&gt;
      &lt;li&gt;Discriminate elements that are 1) exactly zero; 2) small, but not zero.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(L^\infty\) max norm&lt;/strong&gt;: \(\parallel\mathbf{x}\parallel_\infty=\max_i\mid x_i\mid\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Frobenius norm&lt;/strong&gt;: &lt;em&gt;measure size of matrix&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Analogous to \(L^2\) of a vector&lt;/li&gt;
      &lt;li&gt;Dot product in terms of norms \(\mathbf{x}^\intercal\mathbf{y}=\parallel\mathbf{x}\parallel_2\parallel\mathbf{y}\parallel_2\cos\theta\)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;\(\parallel A\parallel_F=\sqrt{\sum_{ij}A_{ij}^2}\)&lt;/p&gt;
    &lt;h3 id=&quot;special-kind-of-matrices-and-vectors&quot;&gt;Special kind of matrices and Vectors&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;Diagonal matrix (\(D\))
    &lt;ul&gt;
      &lt;li&gt;\(diag(\mathbf{v})\): square&lt;/li&gt;
      &lt;li&gt;\(diag(\mathbf{v})^{-1}=diag(\left[1/v_1,\dots,1/v_n\right]^\intercal)\).&lt;/li&gt;
      &lt;li&gt;\(diag(\mathbf{v})\mathbf{x}=\mathbf{v}\odot\mathbf{x} \rightarrow x_i*v_i\).&lt;/li&gt;
      &lt;li&gt;non-square: &lt;strong&gt;no inverse&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Symmetric \(A=A^\intercal\)&lt;/li&gt;
  &lt;li&gt;Unit vector (unit norm): \(\parallel\mathbf{x}\parallel_2=1\)&lt;/li&gt;
  &lt;li&gt;Orthogonal: \(\mathbf{x}^\intercal\mathbf{y}=0\) Vectors are perpendicular (90 degrees)
    &lt;ul&gt;
      &lt;li&gt;mutually orthogonal: Set of vectors are orthogonal&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;orthonormal&lt;/strong&gt;: vector is &lt;strong&gt;orthogonal&lt;/strong&gt; and have &lt;strong&gt;unit norm&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;orthogonal matrix&lt;/strong&gt;: square matrix, rows and columns are mutually orthonormal&lt;/p&gt;

\[\begin{align}
    A^\intercal A&amp;amp;=AA^\intercal=I\\
    A^{-1}&amp;amp;=A^\intercal
  \end{align}\]
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;eigendecomposition&quot;&gt;Eigendecomposition&lt;/h3&gt;
&lt;h4 id=&quot;matrix-decomposition&quot;&gt;Matrix Decomposition&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Eigenvectors (\(\mathbf{v}\) vector)&lt;/li&gt;
  &lt;li&gt;Eigenvalues (\(\lambda\) scalar)&lt;/li&gt;
&lt;/ol&gt;

\[A\mathbf{v}=\lambda\mathbf{v}\]

&lt;h4 id=&quot;eigendecomposition-1&quot;&gt;Eigendecomposition&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;\(\mathbf{v}^{-1}\) ,linear independent eigenvectors&lt;/li&gt;
  &lt;li&gt;\(\mathbf{\lambda}\), corresponding eigenvalue&lt;/li&gt;
&lt;/ol&gt;

\[A=\mathbf{v}diag(\mathbf{\lambda})\mathbf{v}^{-1}\]

&lt;p&gt;&lt;strong&gt;Not every matrix can be decomposed&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;real-symmetric-matrix&quot;&gt;Real Symmetric matrix&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;\(Q\), orthogonal matrix&lt;/li&gt;
  &lt;li&gt;\(\Lambda\), diagonal matrix&lt;/li&gt;
&lt;/ol&gt;

\[A=Q\Lambda Q^\intercal\]

&lt;p&gt;&lt;strong&gt;Not defined for non-squared matrices&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;singular-value-decomposition-svd&quot;&gt;Singular Value Decomposition (SVD)&lt;/h3&gt;
&lt;p&gt;Itâ€™s more generally applicable&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(D\), diagonal matrix (singular values=\(diag(D)\), left-singular vector and right-singular vector are the columns of \(U\) and \(V\) respectively.)&lt;/li&gt;
  &lt;li&gt;\(U\) and \(V\), orthogonal matrices&lt;/li&gt;
&lt;/ol&gt;

\[A=UDV^\intercal\]

\[m\times n = (m\times m) (m\times n) (n\times n)\]

&lt;p&gt;&lt;strong&gt;Useful to partially generalize matrix inversion to non-square matrices.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-moore-penrose-pseudoinverse&quot;&gt;The Moore-Penrose Pseudoinverse&lt;/h3&gt;
&lt;p&gt;Matrix inversion &lt;strong&gt;not defined&lt;/strong&gt; for non-square matrices, these can be calculated with this method.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;real (pseudoinverse): \(A^+=\lim_{\alpha\searrow 0}(A^\intercal A+\alpha I)^{-1}A^\intercal\)&lt;/li&gt;
  &lt;li&gt;practical \(A^+=VD^+U^\intercal\)&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;\(U, D, V\): singular value decomposition of \(A\)&lt;/li&gt;
  &lt;li&gt;\(D^+\): diagonal matrix. Take \(D\) and get the &lt;strong&gt;reciprocal&lt;/strong&gt; of its nonzero element and take the &lt;strong&gt;transpose&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;trace-operator&quot;&gt;Trace operator&lt;/h3&gt;

&lt;h3 id=&quot;determinant&quot;&gt;Determinant&lt;/h3&gt;</content><author><name></name></author><category term="Math" /><summary type="html">Some interesting links: Matrix cookbook Matrix derivatives</summary></entry><entry><title type="html">Probability and Information Theory</title><link href="/blog/2019/probability/" rel="alternate" type="text/html" title="Probability and Information Theory" /><published>2019-05-15T22:41:19-04:00</published><updated>2019-05-15T22:41:19-04:00</updated><id>/blog/2019/probability</id><content type="html" xml:base="/blog/2019/probability/">&lt;p&gt;Some interesting links:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;(http://www.tina-vision.net/docs/memos/2003-003.pdf)&quot;&gt;Product and convolution of gaussians&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;(https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf)&quot;&gt;Multivariate Gaussian&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;(http://www.herbrich.me/papers/EP.pdf)&quot;&gt;EP with Gaussians&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notes of &lt;a href=&quot;(http://www.deeplearningbook.org/contents/linear_algebra.html)&quot;&gt;chapter 3&lt;/a&gt; of Deep Learning book.&lt;/p&gt;</content><author><name></name></author><category term="Math" /><summary type="html">Some interesting links: Product and convolution of gaussians Multivariate Gaussian EP with Gaussians</summary></entry></feed>